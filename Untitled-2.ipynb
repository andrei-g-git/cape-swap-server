{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image:  \n",
      " [[[50 36 30]\n",
      "  [51 37 31]\n",
      "  [46 31 28]\n",
      "  ...\n",
      "  [18 15 11]\n",
      "  [17 14  9]\n",
      "  [16 13  8]]\n",
      "\n",
      " [[53 39 33]\n",
      "  [48 34 28]\n",
      "  [49 34 31]\n",
      "  ...\n",
      "  [17 14 10]\n",
      "  [17 14  9]\n",
      "  [17 14  9]]\n",
      "\n",
      " [[60 47 39]\n",
      "  [52 39 31]\n",
      "  [50 36 30]\n",
      "  ...\n",
      "  [16 13  9]\n",
      "  [18 15 10]\n",
      "  [16 13  8]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 2  5  9]\n",
      "  [ 0  3  7]\n",
      "  [ 1  4  8]\n",
      "  ...\n",
      "  [ 0  5  4]\n",
      "  [ 2  4  4]\n",
      "  [ 2  4  4]]\n",
      "\n",
      " [[ 1  4  8]\n",
      "  [ 2  5  9]\n",
      "  [ 0  3  7]\n",
      "  ...\n",
      "  [ 1  6  5]\n",
      "  [ 0  5  4]\n",
      "  [ 0  5  4]]\n",
      "\n",
      " [[ 1  4  8]\n",
      "  [ 2  5  9]\n",
      "  [ 1  4  8]\n",
      "  ...\n",
      "  [ 0  4  3]\n",
      "  [ 0  5  4]\n",
      "  [ 2  7  6]]]\n",
      "detections:   \n",
      " [label_id: 0\n",
      "score: 0.9087624549865723\n",
      "location_data {\n",
      "  format: RELATIVE_BOUNDING_BOX\n",
      "  relative_bounding_box {\n",
      "    xmin: 0.42138978838920593\n",
      "    ymin: 0.14916542172431946\n",
      "    width: 0.13610205054283142\n",
      "    height: 0.13612109422683716\n",
      "  }\n",
      "  relative_keypoints {\n",
      "    x: 0.4629811644554138\n",
      "    y: 0.1939154416322708\n",
      "  }\n",
      "  relative_keypoints {\n",
      "    x: 0.5162215828895569\n",
      "    y: 0.18930497765541077\n",
      "  }\n",
      "  relative_keypoints {\n",
      "    x: 0.49974802136421204\n",
      "    y: 0.22078736126422882\n",
      "  }\n",
      "  relative_keypoints {\n",
      "    x: 0.5001727938652039\n",
      "    y: 0.24623098969459534\n",
      "  }\n",
      "  relative_keypoints {\n",
      "    x: 0.42528966069221497\n",
      "    y: 0.21662358939647675\n",
      "  }\n",
      "  relative_keypoints {\n",
      "    x: 0.5409567356109619\n",
      "    y: 0.2015720158815384\n",
      "  }\n",
      "}\n",
      "]\n",
      "node tip:  \n",
      "x: 0.49974802136421204\n",
      "y: 0.22078736126422882\n",
      "\n",
      "[[[50 36 30]\n",
      "  [51 37 31]\n",
      "  [46 31 28]\n",
      "  ...\n",
      "  [18 15 11]\n",
      "  [17 14  9]\n",
      "  [16 13  8]]\n",
      "\n",
      " [[53 39 33]\n",
      "  [48 34 28]\n",
      "  [49 34 31]\n",
      "  ...\n",
      "  [17 14 10]\n",
      "  [17 14  9]\n",
      "  [17 14  9]]\n",
      "\n",
      " [[60 47 39]\n",
      "  [52 39 31]\n",
      "  [50 36 30]\n",
      "  ...\n",
      "  [16 13  9]\n",
      "  [18 15 10]\n",
      "  [16 13  8]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 2  5  9]\n",
      "  [ 0  3  7]\n",
      "  [ 1  4  8]\n",
      "  ...\n",
      "  [ 0  5  4]\n",
      "  [ 2  4  4]\n",
      "  [ 2  4  4]]\n",
      "\n",
      " [[ 1  4  8]\n",
      "  [ 2  5  9]\n",
      "  [ 0  3  7]\n",
      "  ...\n",
      "  [ 1  6  5]\n",
      "  [ 0  5  4]\n",
      "  [ 0  5  4]]\n",
      "\n",
      " [[ 1  4  8]\n",
      "  [ 2  5  9]\n",
      "  [ 1  4  8]\n",
      "  ...\n",
      "  [ 0  4  3]\n",
      "  [ 0  5  4]\n",
      "  [ 2  7  6]]]\n",
      "all done\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# file_1 = open('images/spiderman.jpg', 'rb')\n",
    "file_1 = cv2.imread('images/spiderman.jpg')\n",
    "\n",
    "\n",
    "# IMAGE_FILES = [\n",
    "#     file_1\n",
    "# ]\n",
    "IMAGE_FILES = [\n",
    "    'images/spiderman.jpg'\n",
    "]\n",
    "\n",
    "with mp_face_detection.FaceDetection(\n",
    "    model_selection=1,\n",
    "    min_detection_confidence=0.5\n",
    ") as face_detection:\n",
    "    for index, file in enumerate(IMAGE_FILES):\n",
    "        image = cv2.imread(file)\n",
    "        print('image:  \\n', image)\n",
    "        results = face_detection.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        print('detections:   \\n', results.detections)\n",
    "        if not results.detections:\n",
    "            continue\n",
    "        annotated_image = image.copy()\n",
    "        for detection in results.detections:\n",
    "            print('node tip:  ')\n",
    "            print(\n",
    "                mp_face_detection.get_key_point(\n",
    "                    detection, \n",
    "                    mp_face_detection.FaceKeyPoint.NOSE_TIP\n",
    "                )\n",
    "            )   \n",
    "            mp_drawing.draw_detection(annotated_image, detection)\n",
    "\n",
    "        print(annotated_image)\n",
    "\n",
    "        cv2.imwrite('images/annotated_image_' + str(index) + '.png', annotated_image)    \n",
    "\n",
    "\n",
    "print('all done')     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
