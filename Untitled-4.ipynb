{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BBox(x=588, y=326, w=333, h=333)]\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Optional, TypedDict, List\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "\n",
    "@dataclass\n",
    "class PredictOutput:\n",
    "    bboxes: list[list[int | float]] = field(default_factory=list)\n",
    "    masks: list[Image.Image] = field(default_factory=list)\n",
    "    preview: Optional[Image.Image] = None\n",
    "\n",
    "\n",
    "def mediapipe_predict(\n",
    "    model_type: str, image: Image.Image, confidence: float = 0.3\n",
    ") -> PredictOutput:\n",
    "    mapping = {\n",
    "        \"mediapipe_face_short\": partial(mediapipe_face_detection, 0),\n",
    "        \"mediapipe_face_full\": partial(mediapipe_face_detection, 1),\n",
    "        \"mediapipe_face_mesh\": mediapipe_face_mesh,\n",
    "        \"mediapipe_face_mesh_eyes_only\": mediapipe_face_mesh_eyes_only,\n",
    "    }\n",
    "    if model_type in mapping:\n",
    "        func = mapping[model_type]\n",
    "        return func(image, confidence)\n",
    "    msg = f\"[-] ADetailer: Invalid mediapipe model type: {model_type}, Available: {list(mapping.keys())!r}\"\n",
    "    raise RuntimeError(msg)\n",
    "\n",
    "\n",
    "def mediapipe_face_detection(\n",
    "    model_type: int, image: Image.Image, confidence: float = 0.3\n",
    ") -> PredictOutput:\n",
    "    #import mediapipe as mp\n",
    "\n",
    "    img_width, img_height = image.size\n",
    "\n",
    "    mp_face_detection = mp.solutions.face_detection\n",
    "    draw_util = mp.solutions.drawing_utils\n",
    "\n",
    "    img_array = np.array(image)\n",
    "\n",
    "    with mp_face_detection.FaceDetection(\n",
    "        model_selection=model_type, min_detection_confidence=confidence\n",
    "    ) as face_detector:\n",
    "        pred = face_detector.process(img_array)\n",
    "\n",
    "    if pred.detections is None:\n",
    "        return PredictOutput()\n",
    "\n",
    "    preview_array = img_array.copy()\n",
    "\n",
    "    bboxes = []\n",
    "    for detection in pred.detections:\n",
    "        draw_util.draw_detection(preview_array, detection)\n",
    "\n",
    "        bbox = detection.location_data.relative_bounding_box\n",
    "        x1 = bbox.xmin * img_width\n",
    "        y1 = bbox.ymin * img_height\n",
    "        w = bbox.width * img_width\n",
    "        h = bbox.height * img_height\n",
    "        x2 = x1 + w\n",
    "        y2 = y1 + h\n",
    "\n",
    "        bboxes.append([x1, y1, x2, y2])\n",
    "\n",
    "    masks = create_mask_from_bbox(bboxes, image.size)\n",
    "    preview = Image.fromarray(preview_array)\n",
    "\n",
    "    return PredictOutput(bboxes=bboxes, masks=masks, preview=preview)\n",
    "\n",
    "\n",
    "def create_mask_from_bbox(\n",
    "    bboxes: list[list[float]], shape: tuple[int, int]\n",
    ") -> list[Image.Image]:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "        bboxes: list[list[float]]\n",
    "            list of [x1, y1, x2, y2]\n",
    "            bounding boxes\n",
    "        shape: tuple[int, int]\n",
    "            shape of the image (width, height)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        masks: list[Image.Image]\n",
    "        A list of masks\n",
    "\n",
    "    \"\"\"\n",
    "    masks = []\n",
    "    for bbox in bboxes:\n",
    "        mask = Image.new(\"L\", shape, 0)\n",
    "        mask_draw = ImageDraw.Draw(mask)\n",
    "        mask_draw.rectangle(bbox, fill=255)\n",
    "        masks.append(mask)\n",
    "    return masks\n",
    "\n",
    "\n",
    "\n",
    "def mediapipe_face_mesh():\n",
    "    pass\n",
    "        \n",
    "        \n",
    "def mediapipe_face_mesh_eyes_only():\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "output_object = mediapipe_predict(\n",
    "    'mediapipe_face_full',\n",
    "    Image.open('images/1.jpeg')\n",
    ")\n",
    "\n",
    "masks = output_object.masks\n",
    "\n",
    "mask_1 = masks[0]\n",
    "\n",
    "\n",
    "#this shouldn't be necessary, I only want the bbox which is arealy calculated in one of the face detection functions\n",
    "cv_mask = np.array(mask_1)\n",
    "contours, _ = cv2.findContours(cv_mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "@dataclass\n",
    "class BBox:\n",
    "    x:int\n",
    "    y: int\n",
    "    w: int\n",
    "    h: int\n",
    "bboxes:List[BBox] = []\n",
    "i = 0\n",
    "for contour in contours:\n",
    "    _x, _y, _w, _h = cv2.boundingRect(contour)\n",
    "    bbox = BBox(_x, _y, _w, _h)\n",
    "    bboxes.append(bbox)\n",
    "    i += 1\n",
    "\n",
    "print(bboxes)\n",
    "\n",
    "#display(mask_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
